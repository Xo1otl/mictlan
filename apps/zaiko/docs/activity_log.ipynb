{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1\n",
    "\n",
    "- 課題2が終わってから`internal/apiserver/echo.go`にエンドポイントを追加した\n",
    "```go\n",
    "e.GET(\"/\", func(c echo.Context) error {\n",
    "\treturn c.String(200, \"AWS\")\n",
    "})\n",
    "```\n",
    "\n",
    "## 課題2\n",
    "\n",
    "### 1. `auth` モジュールの実装\n",
    "\n",
    "- **目的**: 認証サーバーとバックエンドサーバーを分離し、バックエンドではトークンの検証のみを行う設計にする。\n",
    "- **実施内容**:\n",
    "    - バックエンドで必要な認証処理を行うミドルウェアを作成。\n",
    "        - 過去に JWT 認証で使用したエンティティ (`Token`, `Claims`) とインターフェース (`TokenService`) を `internal/auth/*` に再利用。\n",
    "        - ミドルウェア `internal/auth/echomiddleware.go` をDigest認証に合わせて微修正。\n",
    "\n",
    "### 2. `iam` モジュールの実装\n",
    "\n",
    "- **目的**: Digest 認証では完全なステートレス化が難しく、認証とログインの分離が困難であるため、認証関連の処理を `iam` (Identity and Access Management) モジュールとして分離。\n",
    "- **実施内容**:\n",
    "    - `internal/iam/digest.go` で初期の nonce 発行 (`Init`) とトークンのパース (`Parse`) を行う `Digest` 構造体を開発。\n",
    "    - 以下のインターフェースを定義:\n",
    "        - アカウント情報を取得する `AccountRepo`。\n",
    "        - リプレイ攻撃防止のための nonce カウント (`Nc`) を管理・検証する `DigestNcRepo`。\n",
    "        - nonce の生成と改ざん防止のための検証を行う `NonceService`。\n",
    "        - クライアントからの Digest レスポンスを検証する `DigestTokenValidator`。\n",
    "    - 具体的なサービスを実装:\n",
    "        - MD5 を用いてトークンを検証する `MD5DigestValidator` (`internal/iam/validator.go`)。\n",
    "        - nonce カウント (`Nc`) をメモリ上で管理する `InMemoryDigestNcRepo` (`internal/iam/inmemory.go`)。\n",
    "        - HMAC を用いて nonce を生成・検証する `HMACNonceService` (`internal/iam/nonceservice.go`)。\n",
    "        - アカウント情報を取得する `InMemoryAccountRepo` (`internal/iam/inmemory.go`)。\n",
    "    - Digest 認証のチャレンジとレスポンスの流れを処理するミドルウェア `EchoDigestMiddleware` を実装 (`internal/iam/echodigestmiddleware.go`)。\n",
    "    - Nc等の解放していないリソースがあるから修正いる\n",
    "\n",
    "### 3. `apiserver` モジュールの実装\n",
    "\n",
    "- **目的**: API サーバーを設定し、依存性の注入とルートの登録を行う。\n",
    "- **実施内容**:\n",
    "    - `internal/apiserver/echo.go` にて:\n",
    "        - Echo サーバーの初期化。\n",
    "        - CORS 設定の構成。\n",
    "        - `iam` の各コンポーネント（アカウントリポジトリ、nonce サービス、バリデータなど）の依存性注入を設定。\n",
    "        - ミドルウェアチェーンに `iam.EchoDigestMiddleware` と `auth.EchoMiddleware` を追加。\n",
    "        - ルート（例：`/secret` エンドポイント）の登録。\n",
    "        - サーバーの起動。\n",
    "\n",
    "### 4. 参考文献\n",
    "\n",
    "- [Digest認証の仕様](https://datatracker.ietf.org/doc/html/rfc7616)\n",
    "    - `The nc value is the hexadecimal count of the number of requests (including the current request) that the client has sent with the noncevalue in this request. `\n",
    "- [Digest認証日本語訳](https://tex2e.github.io/rfc-translater/html/rfc7616.html)\n",
    "- [Digest認証日本語解説](https://kunishi.gitbook.io/web-application-textbook/storage)\n",
    "- [RubyのDigest Client](https://www.rubydoc.info/gems/net-http-digest_auth/1.1.1/Net/HTTP/DigestAuth)\n",
    "\n",
    "## 課題3\n",
    "\n",
    "### stockモジュールの実装\n",
    "\n",
    "- **目的**: 在庫管理システムのドメインに基づき、EventSourcing と CQRS を採用した stock モジュールを実装。\n",
    "  \n",
    "- **ドメイン設計を行った**:\n",
    "    - `stock`モジュール内で「stock」がすべての主語となる命名にした。\n",
    "        - 例: Event は `StockEvent`、Aggregate は `StockAggregate`、Add 関数は `AddStock` という形で、主語が省略されている。\n",
    "        - Repository Pattern に倣い、具体的なプレフィックスがつく構造。例えば `UserRepository` と同じように考えているけど、主語が省略されている。\n",
    "    - `producer` や `consumer` の設計も Repository Pattern と類似。ただし、`command service` 限定の処理に限定。\n",
    "    - `query service` は、projection された read model に対して repository pattern を用いてデータを取得する簡易な設計。\n",
    "\n",
    "- **projection の取り扱いを考えた**:\n",
    "    - Projection を別サービスにすることも検討したが、command service が aggregate した結果を用いれば十分と判断。\n",
    "    - そのため、`command service` が projection の処理を兼任し、aggregate の結果を produce。\n",
    "    - Kafka Connect を用いて、aggregate のトピックを consume し、read model に反映する予定だが、いったんmockを作って全部動作確認した。\n",
    "    \n",
    "- **Mockサービスを実装**:\n",
    "    - EventProducerを実装\n",
    "    - EventConsumerを実装\n",
    "    - Repositoryを実装\n",
    "    - すべてInMemoryEventStoreとして実装した\n",
    "\n",
    "- **price と sales の扱いを考え直した**:\n",
    "    - もともと文字列だったが、480.0という数字にする必要があることに気づいた\n",
    "    - 金額のような精度が求められる計算では浮動小数点による誤差を考える必要があることを思い出した\n",
    "    - 高精度な計算が必要と判断し、decimal ライブラリを使用して金額計算を実装しなおした\n",
    "    \n",
    "- **Kafkaを準備**:\n",
    "    - dockerを使用してredpandaとredpanda consoleを立てた\n",
    "    - 過去に趣味でかいたKafkaのdocker composeを再利用\n",
    "    - zaiko.stockのzaoko.stock_projectionの二つのtopicとschemaを用意した\n",
    "        - `rpk --brokers redpanda:9092 topic create zaiko.stock.commands`\n",
    "        - `rpk --brokers redpanda:9092 topic create zaiko.stock.projections`\n",
    "    - valueのstrategyはtopic&record, avroを使用\n",
    "        - zaiko.stockは在庫管理における様々なイベントを持ち、すべて型が異なる\n",
    "        - zaoko.stock_projectionは拡張性を考えて設計\n",
    "    - keyのstrategyは、record毎に代わるわけではないと判断してtopicだけの方\n",
    "    \n",
    "- **具体的なサービスを実装**:\n",
    "    - avro schemaを学習しながら書いた\n",
    "    - KafkaClientのPoCコードを作成\n",
    "        - `kafka_test.go`にprojection用のeventをproduceするテスト関数と、consumeするテスト関数を用意した\n",
    "        - magic byteがないとredpanda console上で表示できないことがわかり、修正した\n",
    "    - KafkaProducerを実装\n",
    "        - avroのschemaのkeyはsubにすべきなので、すべてのentityが正しくsubを持つよう修正、echorouteではMockの認証claimをセットするようにした\n",
    "    - KafkaConsumerを実装\n",
    "        - kgo.PollFetchをgoroutineでループしており、リアルタイムにeventが更新される\n",
    "        - mutexを使用し、eventの更新中はrecordsをロックしている\n",
    "    - MockのKafkaConnectorを書いた\n",
    "        - yamlは手書きせずにpythonで生成した\n",
    "        - 最初はstdoutに出力するmock connectorを書いた\n",
    "    - Query Serviceのデータベースとしてmysqlを採用\n",
    "        - Elasticsearch, Meilisearch等を調べてどれにするか迷った\n",
    "        - 最終的に全文検索エンジンはメモリが足りないず不要と判断した\n",
    "        - docker-compose.yamlもpythonで生成\n",
    "    - GrafanaでMysqlの状態を確認\n",
    "        - explore機能でphpmyadminのような使い方をするだけでも割と便利\n",
    "    - Mysql用のKafkaConnectorを書いた\n",
    "        - kafka connectorもpythonで生成\n",
    "        - eventには新しいsalesの結果とstocksが入っているので、それをmysqlに反映する\n",
    "        - mysqlのinit scriptも一部pythonで生成してミスをなくしている\n",
    "    - Repository Adapterを`mysql.go`に実装\n",
    "\n",
    "- **反省点**\n",
    "    - stocksをmapにしているが、こういうのはmapのarrayとして扱う方が拡張性が高い気もする\n",
    "    - kafkaだけではkeyによるフィルタリングもできないため不自然な処理になっている\n",
    "        - cassandraにexportしてconsumerはcassandraからイベントを取得するようにするか迷った\n",
    "        - connector書いて、eventconsumerのadapterを用意するだけなので実装は現実的\n",
    "        - event sourcingについて調べてもkafkaにproduceしてcassandraにexportする方法について実践的な記事や動画が見当たらないため慎重になった\n",
    "        - kafka stream, ksqlDB, apache flink等の例があるが、java platformは大体重いので手軽に利用できない、Materializeはrust製のため使ってみたいが、cloud版のみ\n",
    "        - partitionを増やしてkeyの存在するpartitionに対してのみクエリを行えば効率化でき、snapshottingも利用すればさらに効率化可能なためkafkaだけでもいいかもしれない\n",
    "        - keyごとのpartitionというのが現実的なのかどうかわからない\n",
    "    - redpandaもmysqlもproduction環境ではなく認証もない状態であること\n",
    "        - helmを勉強してkubernetsクラスタにしたり、分散処理やnamespaceや認証などの設定が必要\n",
    "\n",
    "### 確認ポイント\n",
    "\n",
    "- **APIとデータベースの関係性**:\n",
    "    - APIはデータベースと連携することでステートレスを実現できる\n",
    "- **HTTP メソッドと API の理解**:\n",
    "    - HTTP メソッド（GET、POST、DELETE など）の使い方と意味を理解。\n",
    "    - curl コマンドの `-d` オプションで POST リクエストを送信できることを学習。\n",
    "- **API の実行と確認**:\n",
    "    - 実装した5つのAPIを、curl コマンドを用いて同じ結果が得られることを確認。\n",
    "    - 異常系（不正な値のリクエストやエラー処理）にも対応するよう実装。\n",
    "    - 価格の計算精度や変数ごとの 0 の扱いに注意し、関連しないメソッドに対してもエラーを出すように設定。\n",
    "\n",
    "### 参考文献\n",
    "\n",
    "- [avorについて](https://docs.oracle.com/cd/E35584_01/html/GettingStartedGuide/avroschemas.html)\n",
    "- [プログラムの計算精度](https://zenn.dev/sdb_blog/articles/01_plus_02_does_not_equal_03)\n",
    "- [decimalについて](https://engineering.mercari.com/blog/entry/20201203-basis-point/)\n",
    "- [decimalパッケージ](https://github.com/shopspring/decimal)\n",
    "- [Event Driven Architecture](https://aws.amazon.com/what-is/eda/)\n",
    "- [Kafka Client](https://docs.redpanda.com/redpanda-labs/clients/docker-go/)\n",
    "- [redpanda connect mysql](https://docs.redpanda.com/redpanda-connect/components/processors/sql_raw/?tab=tabs-2-table-insert-mysql)\n",
    "- [event sourcing](https://youtube.com/playlist?list=PLa7VYi0yPIH1TXGUoSUqXgPMD2SQXEXxj)\n",
    "- [ES and CQRS](https://youtu.be/MYD4rrIqDhA)\n",
    "- [bloblang](https://docs.redpanda.com/redpanda-connect/guides/bloblang/methods/#key_values)\n",
    "- [multi sql insert(not supported)](https://github.com/redpanda-data/connect/issues/1495)\n",
    "- [cassandra db](https://www.scylladb.com/)\n",
    "- [cassandra output connector](https://docs.redpanda.com/redpanda-connect/components/outputs/cassandra/)\n",
    "- [influx db](https://github.com/influxdata/influxdb)\n",
    "- [stored procedure](https://dev.mysql.com/doc/refman/8.0/ja/create-procedure.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
