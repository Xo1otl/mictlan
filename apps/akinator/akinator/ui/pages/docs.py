import streamlit as st

r"""
# アキネーターの仕組み

アキネーターの仕組みは、`質疑応答`と`学習`の２つの部分に別れています！

## 1. `質疑応答`

質疑応答は、`適切な質問の選択`と`出現確率分布の更新`と`計算の最適化`の３つの部分に分かれています！

### I. `適切な質問の選択`
最適な質問は、情報エントロピーを計算して行われています

情報エントロピーは**質問ごと**に計算され、**最もエントロピーが低くなる質問**が選択されます

例えば、**3つのケース**（りんご、バナナ、スイカ）と**5つの選択肢**（はい、多少はい、わからない、多少いいえ、いいえ）がある時、**重たいですか？** という質問に対して、以下のような計算が行われます：

1. **初期確率**：
   $$
   P(\text{りんご}) = P(\text{バナナ}) = P(\text{スイカ}) = \frac{1}{3}
   $$

2. **選択肢の確率**：
   例えば、選択肢 "はい" の確率は：
   $$
   P(\text{はい}) = P(\text{はい} | \text{りんご}) \cdot P(\text{りんご}) + P(\text{はい} | \text{バナナ}) \cdot P(\text{バナナ}) + P(\text{はい} | \text{スイカ}) \cdot P(\text{スイカ})
   $$

3. **事後確率**：
   例えば、選択肢 "はい" が与えられたときのりんごの事後確率は：
   $$
   P(\text{りんご} | \text{はい}) = \frac{P(\text{はい} | \text{りんご}) \cdot P(\text{りんご})}{P(\text{はい})}
   $$

4. **事後エントロピー**：
   例えば、選択肢 "はい" に対する事後エントロピーは：
   $$
   H(X | \text{はい}) = -\sum_{i \in \{\text{りんご}, \text{バナナ}, \text{スイカ}\}} P(\text{case}_i | \text{はい}) \log_2 P(\text{case}_i | \text{はい})
   $$

5. **全体の事後エントロピー**：
   $$
   H(X | C) = \sum_{j \in \{\text{はい}, \text{多少はい}, \text{わからない}, \text{多少いいえ}, \text{いいえ}\}} P(c_j) \cdot H(X | c_j)
   $$

6. **情報利得**：
   $$
   \text{IG}(C; X) = H(X) - H(X | C)
   $$
   
   ここで、$ H(X) $は初期エントロピーで、等確率の場合：
   $$
   H(X) = -\sum_{i=1}^{3} \frac{1}{3} \log_2 \frac{1}{3} = \log_2 3
   $$

これらの計算を、すべての質問に対して行い、もっとも情報利得が大きくなる質問を選択します！

### II. `出現確率分布の更新`

出現確率の更新は、選択肢が入力された後に行われます！

エントロピーを計算した時に、ある質問を行った時に、ある選択肢が選ばれたという条件の元でのそれぞれの場合の出現確率分布が、すべての組み合わせについて計算されています。

このデータを保持しておき、選択肢が入力された後に、その条件付き確率を新しい出現確率分布とします！

そして、クリア条件として、7割以上の確率がある場合には、雑にそのケースを回答としています！

つまりこのアキネーターさんは十分なデータがある時に、7割以上の確率で正解できるということです！

これは設定でなんぼでも引き上げられるのですが、代わりに必要な質問数が増えます。

### III. `計算の最適化`

質問と選択肢を固定してすべての場合について条件付き確率を求めて、選択肢が出現する期待値をすべての場合との重み付き和で求めて...なんだかこんがらがりますね！

これを効率よく計算するために、テンソルという一般化を行っております。

それぞれの確率は、質問と場合と選択肢によってindexされます。つまりそれぞれの確率は、どの質問なのか、どの場合なのか、どの選択肢なのか、どの確率なのか、という4次元のテンソルと考えることができます！

そして、それぞれの場合について考えるのではなく、4次元テンソル同士の演算と捉えることで、計算がわかりやすくなります。

また、テンソルについて深く知らなくても、テンソルの操作は以下のようにしてpytorchというライブラリを使えば勝手にGPUでできるようになるので、とても便利です！

```python
@torch.no_grad()
def question_entropies(self) -> torch.Tensor:
    # P(選択肢,場合|質問) = P(選択肢|場合,質問) * P(場合)
    self.context.tensor[:, :, :, self.context.probability_attr_to_idx["p_choice_case_given_question"]] = (
        self.context.tensor[
            :, :, :, self.context.probability_attr_to_idx["p_choice_given_case_question"]]
        * self.context.p_case_tensor.unsqueeze(0).unsqueeze(2)
    )

    # P(選択肢|質問) = Σ_場合 P(選択肢,場合|質問)
    self.context.tensor[:, :, :, self.context.probability_attr_to_idx["p_choice_given_question"]] = (
        self.context.tensor[:, :, :, self.context.probability_attr_to_idx["p_choice_case_given_question"]].sum(
            dim=1, keepdim=True)
    )

    # P(場合|選択肢,質問) = P(選択肢,場合|質問) / P(選択肢|質問) (ベイズの定理より)
    self.context.tensor[:, :, :, self.context.probability_attr_to_idx["p_case_given_choice_question"]] = (
        self.context.tensor[
            :, :, :, self.context.probability_attr_to_idx["p_choice_case_given_question"]]
        / self.context.tensor[:, :, :, self.context.probability_attr_to_idx["p_choice_given_question"]]
    )

    # エントロピーの計算に必要な条件付き確率等をテンソルから取得
    p_case_given_choice_question = self.context.tensor[
        :, :, :, self.context.probability_attr_to_idx["p_case_given_choice_question"]]
    log_p_case_given_choice_question = torch.where(p_case_given_choice_question > 0, torch.log2(
        p_case_given_choice_question), torch.zeros_like(p_case_given_choice_question))

    # 存在しない組み合わせの項はベイズの定理で0除算され値がnanになるのでnansumを使って除外する
    # H(選択肢,質問) = - Σ_場合 P(場合|選択肢,質問) * log2(P(場合|選択肢,質問))
    entropy_given_choice_question = (
        -p_case_given_choice_question * log_p_case_given_choice_question).nansum(dim=1)
    # H(質問) = Σ_選択肢 H(選択肢,質問) * P(選択肢|質問)
    entropy_given_question = (entropy_given_choice_question * self.context.tensor[
        :, :, :, self.context.probability_attr_to_idx["p_choice_given_question"]][:, 0, :]).nansum(dim=1)
    return entropy_given_question
```

また、すべての場合ですべての質問に対しての選択肢のデータがあるわけではないことから、未知の質問に対する選択肢の出現確率は推定しなければなりません。

これは、その質問に対して回答が用意されているすべてのデータから、そのデータの出現確率と選択肢が選ばれる確率の加重平均をとって推定しています。

つまり、ある主人公は男ですか？という質問に対して、データが少なすぎてはいという回答しかない場合、未知のデータに対しても男ですかという質問には必ずはいが選ばれるという推定が行われています。

そういう事情を考慮して、playやtrainを行っていただけると幸いです。


## 2. `学習`

一応アキネーターは機械学習の一種っぽいので学習とよんでいますが、ただ統計とってるだけです

遊んだ結果や、train画面の入力からは、どの場合でどの質問にどの選択肢が選ばれたのか、という情報だけです。

それを集計して、P(場合)やP(選択肢|場合,質問)などの確率分布を計算しています。

# アキネーターの実装

アキネーターの実装では主に、`Clean Architecture`と`CQRS`の考え方を取り入れています！

## I. `Clean Architecture`
Clean Architectureというのは、アプリケーションを内部から外部に向かって、依存関係がなるべく一方向になるように設計することです！(クソ雑)

## II. `CQRS`
今回、追加するデータは質問と場合と選択肢の組み合わせで、読み取るデータはP(場合), P(選択肢|場合,質問)などです

CQRSでは、書き込み用のデータベースと、読み取り用のデータベースを別々に用意して、projectorというアプリケーションを間に作ってデータを変換するという構成を取ります。

書き込みのデータベースでは、どの場合でどの質問にどの選択肢が選ばれたのか、という情報をイベントとして保持します、これにはkafkaというアプリケーションを用います

projector(イベントを集計して読み取りデータの作成を行う)アプリでは、kafkaのイベントをconsumeして非同期に読み取りデータの作成を行います。

読み取り用のデータベースは、用途に応じてベクトルデータベースや全文検索エンジンなどの高機能なものを使用します

ゲームを実行する処理では、どのようなデータがどのように書き込まれたかに関して一切認知せず、出来上がった読み取りデータだけ取得して、それを使ってゲームを実行します

というのが理想的な構成だったんですが、めんどくさいのでmysqlを使って、書き込みはテーブルに、読み取りはviewから行っています。

# アキネーターの画面の実装

今見えてるこの画面なんですが、対して複雑なことはしていません！

でもreducer patternというのをやってみたので紹介します。

reducer patternは、複雑な複合状態を管理するのに用いると便利です。

例えば、train画面では以下のような想定外の状況が考えられます。
* 存在するカテゴリ名で再度追加しようとした時
* カテゴリ名が空の状態で追加しようとした時
* 存在する質問文で再度追加しようとした時
* 質問文が空の状態で追加しようとした時
* 存在する場合名で再度追加しようとした時
* 場合名が空の状態で追加しようとした時
* カテゴリを選択していない状態で質問を選ぼうとした時
* カテゴリを選択していない状態で場合を選ぼうとした時
* カテゴリを選択していない状態で選択肢を選ぼうとした時
* 質問を選択していない状態で選択肢を選ぼうとした時
* 場合を選択していない状態で選択肢を選ぼうとした時
* 存在しない選択肢を選ぼうとした時
* 存在しない質問を選ぼうとした時
* 存在しない場合を選ぼうとした時
* 存在しないカテゴリを選ぼうとした時
* 選択肢が空の状態で追加しようとした時
* 選択肢のどれかの要素が空の時
* 選択肢の要素が重複している時 (New! 書いてて思いついたけど対応できてない、一応dbの制約的にできないはず)

これらをそれぞれのボタンの処理のところでif文とか書いて全部検証してるとカオスなことになります。

そこで、すべての状態を一つのオブジェクトにまとめて、それを更新する関数を書いて、すべての状態変更を同じ関数で行うことで、状態の変更を一元化します。

一応やってみたんですが、streamlitでやるの結構大変だったんで、編集機能はめんどくさくて実装してません。

ちゃんとやるならreactとかsvelteとかでやるべきだと思いました。

# TODO

* 経験ベイズ木というのがあるらしいが、成長させるために必要な計算が現在の仕組みだと膨大なので、どう扱うのかよくわからない
* 量子コンピュータを用いて計算する方法について考えたい、なんかいける気がする(適当)
"""
