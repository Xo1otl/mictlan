{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    subgraph domain\n",
    "        Indexer[\"Indexer\n",
    "        概要: コンテンツを収集して全文検索インデックスを作成\n",
    "        実装: FileProcessorで処理したコンテンツをUploaderで登録\"] \n",
    "        --> FileProcessor\n",
    "        Indexer --> Uploader\n",
    "\n",
    "        FileProcessor[\"FileProcessor\n",
    "        概要: 様々な形式のコンテンツを収集・加工して検索用データを生成\n",
    "        実装: Collectorで収集した全コンテンツをFormatterで変換\"]\n",
    "        --> Collector\n",
    "        FileProcessor --> Formatter\n",
    "        \n",
    "        Collector[\"Collector\n",
    "        概要: 指定されたソースからコンテンツを収集\n",
    "        実装: コンテンツの取得と読み込みを実行\"]\n",
    "        \n",
    "        Formatter[\"Formatter\n",
    "        概要: 収集したコンテンツから検索に必要な情報を抽出・整形\n",
    "        実装: 指定されたルールでコンテンツを検索用データに変換\"]\n",
    "        \n",
    "        Uploader[\"Uploader\n",
    "        概要: 生成したデータを検索エンジンに登録\n",
    "        実装: 検索エンジンなどにデータを登録\"]\n",
    "    end\n",
    "\n",
    "    subgraph adapter\n",
    "        GitCollector[\"GitCollector\n",
    "        概要: Gitリポジトリからコンテンツを収集\n",
    "        実装: Git Pythonを使用してファイルを取得\"]\n",
    "        --> Collector\n",
    "\n",
    "        DocumentFormatter[\"DocumentFormatter\n",
    "        概要: Notebookファイルを検索に適した形式に変換\n",
    "        実装: 不要なメタデータをstrip\"]\n",
    "        --> Formatter\n",
    "\n",
    "        MeilisearchUploader[\"MeilisearchUploader\n",
    "        概要: Meilisearchにデータを登録\n",
    "        実装: Meilisearch Clientで一括登録\"]\n",
    "        --> Uploader\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol, Iterable\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# Interfaces\n",
    "class Collector(Protocol):\n",
    "    def collect(self) -> Iterable[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        コンテンツの収集を行う\n",
    "        Returns:\n",
    "            Iterable[Tuple[str, str]]: (filepath, content)のタプルのイテラブル\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class Formatter(Protocol):\n",
    "    def format(self, filepath: str, content: str) -> dict:\n",
    "        \"\"\"\n",
    "        コンテンツを検索用データに変換する\n",
    "        Args:\n",
    "            filepath: ファイルパス\n",
    "            content: ファイルの内容\n",
    "        Returns:\n",
    "            dict: 検索用のドキュメント\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class Uploader(Protocol):\n",
    "    def upload(self, documents: list[dict]) -> None:\n",
    "        \"\"\"\n",
    "        検索エンジンにデータを登録する\n",
    "        Args:\n",
    "            documents: アップロード対象のドキュメントリスト\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "# Domain Classes\n",
    "class FileProcessor:\n",
    "    def __init__(self, collector: Collector, formatter: Formatter):\n",
    "        self.collector = collector\n",
    "        self.formatter = formatter\n",
    "\n",
    "    def process(self) -> list[dict]:\n",
    "        documents = []\n",
    "        for filepath, content in self.collector.collect():\n",
    "            document = self.formatter.format(filepath, content)\n",
    "            documents.append(document)\n",
    "        return documents\n",
    "\n",
    "\n",
    "class Indexer:\n",
    "    def __init__(self, processor: FileProcessor, uploader: Uploader):\n",
    "        self.processor = processor\n",
    "        self.uploader = uploader\n",
    "\n",
    "    def index(self) -> None:\n",
    "        documents = self.processor.process()\n",
    "        if documents:\n",
    "            self.uploader.upload(documents)\n",
    "\n",
    "\n",
    "def create_indexer(collector: Collector, formatter: Formatter, uploader: Uploader) -> Indexer:\n",
    "    processor = FileProcessor(collector, formatter)\n",
    "    return Indexer(processor, uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meilisearch\n",
    "\n",
    "\n",
    "class MeilisearchUploader:\n",
    "    def __init__(self, host: str, api_key: str, index_name: str):\n",
    "        self.client = meilisearch.Client(host, api_key)\n",
    "        self.index = self.client.index(index_name)\n",
    "\n",
    "        # 検索可能なフィールドとフィルタリング属性を設定\n",
    "        self.index.update_settings({\n",
    "            'searchableAttributes': [\n",
    "                'content',\n",
    "                'filepath'\n",
    "            ],\n",
    "            'filterableAttributes': [\n",
    "                'ext'\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    def upload(self, documents: list[dict]) -> None:\n",
    "        \"\"\"ドキュメントをMeilisearchにアップロードする\"\"\"\n",
    "        if documents:\n",
    "            self.index.add_documents(documents)\n",
    "            print(f\"Indexed {len(documents)} files successfully\")\n",
    "        else:\n",
    "            print(\"No text files found to index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "from typing import Optional, Iterable, Tuple, List\n",
    "import fnmatch\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "\n",
    "class GitCollector:\n",
    "    def __init__(self, repo_path: str, ignore_patterns: List[str] = []):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            repo_path: GitリポジトリのパスまたはURL\n",
    "                      - ローカル: '/path/to/repo' や 'C:\\\\path\\\\to\\\\repo'\n",
    "                      - リモート: 'https://github.com/user/repo.git' や 'git@github.com:user/repo.git'\n",
    "            ignore_patterns: 除外するファイルのglobパターンのリスト\n",
    "                           例: ['*.pdf', 'test/**/*.py', 'tmp/*']\n",
    "        \"\"\"\n",
    "        self.is_remote = repo_path.startswith(\n",
    "            ('http://', 'https://', 'git@', 'ssh://'))\n",
    "\n",
    "        if self.is_remote:\n",
    "            self.temp_dir = tempfile.mkdtemp()\n",
    "            self.repo = git.Repo.clone_from(repo_path, self.temp_dir)\n",
    "            self.repo_path = self.temp_dir\n",
    "        else:\n",
    "            self.repo_path = repo_path\n",
    "            self.repo = git.Repo(repo_path)\n",
    "            self.temp_dir = None\n",
    "\n",
    "        self.ignore_patterns = ignore_patterns or []\n",
    "\n",
    "    def _should_ignore(self, file_path) -> bool:\n",
    "        \"\"\"\n",
    "        ファイルを無視すべきかどうかを判定する\n",
    "\n",
    "        Args:\n",
    "            file_path: 判定対象のファイルパス（リポジトリルートからの相対パス）\n",
    "\n",
    "        Returns:\n",
    "            bool: 無視すべき場合はTrue\n",
    "        \"\"\"\n",
    "        # Windowsのパス区切り文字をUNIX形式に統一\n",
    "        normalized_path = file_path.replace(os.sep, '/')\n",
    "\n",
    "        for pattern in self.ignore_patterns:\n",
    "            # パターンもUNIX形式に統一\n",
    "            normalized_pattern = pattern.replace(os.sep, '/')\n",
    "\n",
    "            # **/ で始まるパターンの場合は、すべてのサブディレクトリにマッチ\n",
    "            if pattern.startswith('**/'):\n",
    "                if fnmatch.fnmatch(normalized_path, pattern[3:]):\n",
    "                    return True\n",
    "\n",
    "            # パターンに / が含まれる場合は、完全パスでマッチング\n",
    "            if '/' in normalized_pattern:\n",
    "                if fnmatch.fnmatch(normalized_path, normalized_pattern):\n",
    "                    return True\n",
    "            else:\n",
    "                # パターンに / が含まれない場合は、ファイル名のみでマッチング\n",
    "                if fnmatch.fnmatch(os.path.basename(normalized_path), normalized_pattern):\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _read_file_content(self, file_path) -> Optional[str]:\n",
    "        \"\"\"ファイルの内容を読み込む。バイナリファイルの場合はNoneを返す\"\"\"\n",
    "        try:\n",
    "            with open(os.path.join(self.repo_path, file_path), 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        except (UnicodeDecodeError, IOError):\n",
    "            return None\n",
    "\n",
    "    def collect(self) -> Iterable[Tuple]:\n",
    "        \"\"\"Git管理下のファイルとその内容を収集する（ignore_patternsに一致するファイルは除外）\"\"\"\n",
    "        tracked_files = [item[0] for item in self.repo.index.entries]\n",
    "\n",
    "        for file_path in tracked_files:\n",
    "            if not self._should_ignore(file_path):\n",
    "                content = self._read_file_content(file_path)\n",
    "                if content is not None:\n",
    "                    yield file_path, content\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"デストラクタ: リモートの場合、一時ディレクトリを削除\"\"\"\n",
    "        if self.temp_dir and os.path.exists(self.temp_dir):\n",
    "            shutil.rmtree(self.temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "\n",
    "class DocumentFormatter:\n",
    "    def _normalize_source(self, source):\n",
    "        \"\"\"ソースコードの内容を正規化する\"\"\"\n",
    "        if isinstance(source, list):\n",
    "            # リストの場合は各要素を結合して1つの文字列にする\n",
    "            return ''.join(source)\n",
    "        return source\n",
    "\n",
    "    def _clean_notebook_content(self, content: str) -> str:\n",
    "        \"\"\"ipynbファイルから不要なメタデータを削除し、日本語を正規化する\"\"\"\n",
    "        try:\n",
    "            notebook = json.loads(content)\n",
    "\n",
    "            # セルの内容だけを抽出し、不要なメタデータを削除\n",
    "            cleaned_cells = []\n",
    "            for cell in notebook.get('cells', []):\n",
    "                # sourceの内容を正規化\n",
    "                source = self._normalize_source(cell.get('source', []))\n",
    "\n",
    "                cleaned_cell = {\n",
    "                    'cell_type': cell.get('cell_type'),\n",
    "                    'source': source  # リストではなく文字列として保存\n",
    "                }\n",
    "\n",
    "                # outputsは実行結果なので削除（画像データなども含まれる）\n",
    "                if cell.get('cell_type') == 'code':\n",
    "                    cleaned_cell['outputs'] = []\n",
    "\n",
    "                cleaned_cells.append(cleaned_cell)\n",
    "\n",
    "            # 最小限の情報だけを持つノートブックを作成\n",
    "            cleaned_notebook = {\n",
    "                'cells': cleaned_cells,\n",
    "                'nbformat': notebook.get('nbformat', 4),\n",
    "                'nbformat_minor': notebook.get('nbformat_minor', 0),\n",
    "                'metadata': {\n",
    "                    'kernelspec': notebook.get('metadata', {}).get('kernelspec', {})\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # ensure_ascii=Falseで日本語をそのまま出力\n",
    "            return json.dumps(cleaned_notebook, ensure_ascii=False, indent=2)\n",
    "        except json.JSONDecodeError:\n",
    "            return content\n",
    "\n",
    "    def format(self, filepath: str, content: str) -> dict:\n",
    "        \"\"\"検索用ドキュメントを作成する\"\"\"\n",
    "        ext = os.path.splitext(filepath)[1][1:] or 'no-extension'\n",
    "\n",
    "        # ipynbファイルの場合は内容をクリーニング\n",
    "        if ext == 'ipynb':\n",
    "            content = self._clean_notebook_content(content)\n",
    "\n",
    "        return {\n",
    "            'id': str(uuid.uuid4()),\n",
    "            'filepath': filepath,\n",
    "            'content': content,\n",
    "            'ext': ext\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 127 files successfully\n"
     ]
    }
   ],
   "source": [
    "from infra import searchengine\n",
    "\n",
    "collector = GitCollector('https://github.com/riccox/meilisearch-ui', ignore_patterns=[\n",
    "    \"*.min.css\",\n",
    "    \"*-min.css\",\n",
    "    \"*.sum\",\n",
    "    \"known_hosts\",\n",
    "    \"cdk.json\"\n",
    "])\n",
    "formatter = DocumentFormatter()\n",
    "uploader = MeilisearchUploader(\n",
    "    'http://meilisearch:7700', searchengine.MEILI_MASTER_KEY, 'fssearch-poc3')\n",
    "create_indexer(collector, formatter, uploader).index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskInfo(task_uid=440, index_uid='fssearch-poc3', status='enqueued', type='indexDeletion', enqueued_at=datetime.datetime(2024, 11, 12, 17, 22, 53, 179380))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meilisearch.Client('http://meilisearch:7700', searchengine.MEILI_MASTER_KEY).index('mictlan').delete()\n",
    "meilisearch.Client('http://meilisearch:7700', searchengine.MEILI_MASTER_KEY).index('fssearch-poc3').delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
