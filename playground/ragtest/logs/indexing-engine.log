18:15:00,269 graphrag.cli.index INFO Logging enabled at /workspaces/mictlan/playground/ragtest/logs/indexing-engine.log
18:15:00,272 graphrag.cli.index INFO Starting pipeline run for: 20241115-181500, dry_run=False
18:15:00,273 graphrag.cli.index INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "jaahas/gemma-2-9b-it-abliterated",
        "max_tokens": 2048,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "http://ollama:11434/v1",
        "api_version": null,
        "proxy": null,
        "audience": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 2,
        "max_retry_wait": 5.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 4
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "/workspaces/mictlan/playground/ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "/workspaces/mictlan/playground/ragtest/logs",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/workspaces/mictlan/playground/ragtest/output",
        "storage_account_blob_url": null
    },
    "update_index_storage": null,
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.openai.com/v1",
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": {
            "type": "lancedb",
            "db_uri": "output/lancedb",
            "container_name": "==== REDACTED ====",
            "overwrite": false
        },
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false,
        "transient": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "jaahas/gemma-2-9b-it-abliterated",
            "max_tokens": 2048,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://ollama:11434/v1",
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 2,
            "max_retry_wait": 5.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 4
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "jaahas/gemma-2-9b-it-abliterated",
            "max_tokens": 2048,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://ollama:11434/v1",
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 2,
            "max_retry_wait": 5.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 4
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "jaahas/gemma-2-9b-it-abliterated",
            "max_tokens": 2048,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://ollama:11434/v1",
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 2,
            "max_retry_wait": 5.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 4
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "jaahas/gemma-2-9b-it-abliterated",
            "max_tokens": 2048,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://ollama:11434/v1",
            "api_version": null,
            "proxy": null,
            "audience": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 2,
            "max_retry_wait": 5.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 4
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
18:15:00,274 graphrag.index.create_pipeline_config INFO skipping workflows 
18:15:00,275 graphrag.index.run.run INFO Running pipeline
18:15:00,275 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at /workspaces/mictlan/playground/ragtest/output
18:15:00,276 graphrag.index.input.load_input INFO loading input from root_dir=input
18:15:00,276 graphrag.index.input.load_input INFO using file storage for input
18:15:00,278 graphrag.index.storage.file_pipeline_storage INFO search /workspaces/mictlan/playground/ragtest/input for files matching .*\.txt$
18:15:00,278 graphrag.index.input.text INFO found text files from input, found [('book.txt', {})]
18:15:00,282 graphrag.index.input.text INFO Found 1 files, loading 1
18:15:00,283 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'create_final_relationships', 'create_final_text_units', 'create_final_community_reports', 'create_final_documents', 'generate_text_embeddings']
18:15:00,284 graphrag.index.run.run INFO Final # of rows loaded: 1
18:15:00,519 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
18:15:00,525 datashaper.workflow.workflow INFO executing verb create_base_text_units
18:15:01,196 graphrag.index.run.workflow INFO dependencies for create_base_entity_graph: ['create_base_text_units']
18:15:01,197 graphrag.index.run.workflow WARNING Dependency table create_base_text_units not found in storage: it may be a runtime-only in-memory table. If you see further errors, this may be an actual problem.
18:15:01,204 datashaper.workflow.workflow INFO executing verb create_base_entity_graph
18:15:01,214 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://ollama:11434/v1
18:15:01,265 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for jaahas/gemma-2-9b-it-abliterated: TPM=0, RPM=0
18:15:01,265 graphrag.index.llm.load_llm INFO create concurrency limiter for jaahas/gemma-2-9b-it-abliterated: 4
18:16:25,582 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:16:25,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 84.27106668901979. input_tokens=2936, output_tokens=191
18:17:14,604 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:17:14,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 133.30130897200434. input_tokens=2936, output_tokens=409
18:17:23,293 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:17:23,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 141.99994881200837. input_tokens=2935, output_tokens=410
18:17:38,662 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:17:38,664 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 157.35358021198772. input_tokens=2937, output_tokens=440
18:18:28,274 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:18:28,275 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 73.67033550600172. input_tokens=2935, output_tokens=150
18:18:54,230 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:18:54,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 148.64781442598905. input_tokens=2935, output_tokens=427
18:19:33,472 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:19:33,474 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 130.18355836899718. input_tokens=2936, output_tokens=387
18:19:34,39 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:19:34,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 115.380531110015. input_tokens=2936, output_tokens=356
18:20:49,77 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:20:49,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 140.80888758398942. input_tokens=2936, output_tokens=439
18:21:16,942 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:21:16,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 142.71784375602147. input_tokens=2936, output_tokens=428
18:21:46,524 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:21:46,525 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 133.0563109399809. input_tokens=2936, output_tokens=392
18:22:04,650 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:22:04,652 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 150.61591624998255. input_tokens=2936, output_tokens=434
18:23:18,441 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:23:18,443 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 149.36908400300308. input_tokens=2936, output_tokens=450
18:23:27,686 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:23:27,687 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 101.16463949900935. input_tokens=2935, output_tokens=227
18:23:50,580 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:23:50,582 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 153.6431692519982. input_tokens=2936, output_tokens=425
18:24:35,909 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:24:35,911 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 151.26458200399065. input_tokens=2935, output_tokens=446
18:25:24,761 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:25:24,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 126.32379526802106. input_tokens=2936, output_tokens=360
18:25:41,940 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:25:41,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 134.25998085399624. input_tokens=2936, output_tokens=385
18:26:32,886 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:26:32,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 162.3108398669865. input_tokens=2936, output_tokens=486
18:26:51,933 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:26:51,935 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 136.0283776879951. input_tokens=2936, output_tokens=382
18:27:43,114 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:27:43,115 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 70.23000366598717. input_tokens=2936, output_tokens=152
18:28:05,503 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:28:05,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 160.746722728014. input_tokens=2936, output_tokens=444
18:28:13,116 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:28:13,118 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 151.18080820699106. input_tokens=2936, output_tokens=404
18:29:15,486 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:29:15,488 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 143.55826919301762. input_tokens=2936, output_tokens=397
18:29:35,556 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:29:35,558 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 112.44576112099458. input_tokens=2935, output_tokens=274
18:30:15,451 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:30:15,453 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 129.95366878900677. input_tokens=2936, output_tokens=359
18:30:31,77 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:30:31,79 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 137.96482196400757. input_tokens=2935, output_tokens=393
18:31:32,459 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:31:32,460 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 116.90640422899742. input_tokens=2936, output_tokens=345
18:31:58,699 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:31:58,701 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 163.21837931402843. input_tokens=2934, output_tokens=470
18:32:35,363 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:32:35,364 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 139.91496560699306. input_tokens=2934, output_tokens=407
18:33:19,885 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:33:19,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 168.8147223989945. input_tokens=2936, output_tokens=500
18:34:06,766 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:34:06,768 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 154.31229987100232. input_tokens=2936, output_tokens=457
18:34:29,294 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:34:29,295 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 150.5989804349956. input_tokens=2935, output_tokens=434
18:34:44,874 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:34:44,876 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 129.51656241499586. input_tokens=2935, output_tokens=366
18:36:19,985 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \'t know.\'\n\n\'Knew what, my dear?\'\n\n\'Why, that you were a good wife,\' replied Bob.\n\n\'Everybody knows that,\' said Peter.\n\n\'Very well observed, my boy!\' cried Bob. \'I hope they do. "Heartily\nsorry," he said, "for your good wife. If I can be of service to you in\nany way," he said, giving me his card, "that\'s where I live. Pray come\nto me." Now, it wasn\'t,\' cried Bob, \'for the sake of anything he might\nbe able to do for us, so much as for his kind way, that this was quite\ndelightful. It really seemed as if he had known our Tiny Tim, and felt\nwith us.\'\n\n\'I\'m sure he\'s a good soul!\' said Mrs. Cratchit.\n\n\'You would be sure of it, my dear,\' returned Bob, \'if you saw and spoke\nto him. I shouldn\'t be at all surprised--mark what I say!--if he got\nPeter a better situation.\'\n\n\'Only hear that, Peter,\' said Mrs. Cratchit.\n\n\'And then,\' cried one of the girls, \'Peter will be keeping company with\nsome one, and setting up for himself.\'\n\n\'Get along with you!\' retorted Peter, grinning.\n\n\'It\'s just as likely as not,\' said Bob, \'one of these days; though\nthere\'s plenty of time for that, my dear. But, however and whenever we\npart from one another, I am sure we shall none of us forget poor Tiny\nTim--shall we--or this first parting that there was among us?\'\n\n\'Never, father!\' cried they all.\n\n\'And I know,\' said Bob, \'I know, my dears, that when we recollect how\npatient and how mild he was; although he was a little, little child; we\nshall not quarrel easily among ourselves, and forget poor Tiny Tim in\ndoing it.\'\n\n\'No, never, father!\' they all cried again.\n\n\'I am very happy,\' said little Bob, \'I am very happy!\'\n\nMrs. Cratchit kissed him, his daughters kissed him, the two young\nCratchits kissed him, and Peter and himself shook hands. Spirit of Tiny\nTim, thy childish essence was from God!\n\n\'Spectre,\' said Scrooge, \'something informs me that our parting moment\nis at hand. I know it but I know not how. Tell me what man that was whom\nwe saw lying dead?\'\n\nThe Ghost of Christmas Yet to Come conveyed him, as before--though at a\ndifferent time, he thought: indeed there seemed no order in these latter\nvisions, save that they were in the Future--into the resorts of business\nmen, but showed him not himself. Indeed, the Spirit did not stay for\nanything, but went straight on, as to the end just now desired, until\nbesought by Scrooge to tarry for a moment.\n\n\'This court,\' said Scrooge, \'through which we hurry now, is where my\nplace of occupation is, and has been for a length of time. I see the\nhouse. Let me behold what I shall be in days to come.\'\n\nThe Spirit stopped; the hand was pointed elsewhere.\n\n\'The house is yonder,\' Scrooge exclaimed. \'Why do you point away?\'\n\nThe inexorable finger underwent no change.\n\nScrooge hastened to the window of his office, and looked in. It was an\noffice still, but not his. The furniture was not the same, and the\nfigure in the chair was not himself. The Phantom pointed as before.\n\nHe joined it once again, and, wondering why and whither he had gone,\naccompanied it until they reached an iron gate. He paused to look round\nbefore entering.\n\nA churchyard. Here, then, the wretched man, whose name he had now to\nlearn, lay underneath the ground. It was a worthy place. Walled in by\nhouses; overrun by grass and weeds, the growth of vegetation\'s death,\nnot life; choked up with too much burying; fat with repleted appetite. A\nworthy place!\n\nThe Spirit stood among the graves, and pointed down to One. He advanced\ntowards it trembling. The Phantom was exactly as it had been, but he\ndreaded that he saw new meaning in its solemn shape.\n\n\'Before I draw nearer to that stone to which you point,\' said Scrooge,\n\'answer me one question. Are these the shadows of the things that Will\nbe, or are they shadows of the things that May be only?\'\n\nStill the Ghost pointed downward to the grave by which it stood.\n\n\'Men\'s courses will foreshadow certain ends, to which, if persevered in,\nthey must lead,\' said Scrooge. \'But if the courses be departed from, the\nends will change. Say it is thus with what you show me!\'\n\nThe Spirit was immovable as ever.\n\nScrooge crept towards it, trembling as he went; and, following the\nfinger, read upon the stone of the neglected grave his own name,\nEBENEZER SCROOGE.\n\n\'Am I that man who lay upon the bed?\' he cried upon his knees.\n\nThe finger pointed from the grave to him, and back again.\n\n\'No, Spirit! Oh no, no!\'\n\nThe finger still was there.\n\n\'Spirit!\' he cried, tight clutching at its robe, \'hear me! I am not the\nman I was. I will not be the man I must have been but for this\nintercourse. Why show me this, if I am past all hope?\'\n\nFor the first time the hand appeared to shake.\n\n\'Good\n######################\nOutput:'}
18:36:30,376 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:36:30,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 143.61506458499935. input_tokens=2936, output_tokens=433
18:36:49,790 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:36:49,792 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 140.50142074300675. input_tokens=2936, output_tokens=411
18:36:53,689 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:36:53,691 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 128.81872141300119. input_tokens=2936, output_tokens=378
18:38:42,573 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:38:42,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 132.20163731501088. input_tokens=2936, output_tokens=397
18:38:57,372 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:38:57,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 155.99925621101283. input_tokens=2937, output_tokens=431
18:38:57,941 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:38:57,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 128.15435156101012. input_tokens=2937, output_tokens=366
18:39:12,400 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:39:12,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 138.7156744459935. input_tokens=2935, output_tokens=402
18:39:24,284 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:39:24,285 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.342904481018195. input_tokens=34, output_tokens=81
18:39:27,875 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:39:27,876 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.502509185986128. input_tokens=34, output_tokens=81
18:39:54,979 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:39:54,980 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.10470346501097. input_tokens=34, output_tokens=84
18:39:54,986 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:39:54,988 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.58665624601417. input_tokens=34, output_tokens=133
18:40:19,506 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:40:19,507 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 24.51949617601349. input_tokens=34, output_tokens=74
18:40:24,712 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:40:24,714 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 29.73384737499873. input_tokens=34, output_tokens=83
18:40:38,376 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:40:38,377 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 74.09359332101303. input_tokens=34, output_tokens=238
18:40:53,744 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:40:53,745 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 29.03218209600891. input_tokens=34, output_tokens=90
18:41:01,915 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:41:01,916 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 139.3455007489829. input_tokens=2790, output_tokens=354
18:41:06,338 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:41:06,339 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.962415788002545. input_tokens=34, output_tokens=82
18:41:24,905 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:41:24,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 65.40035923302639. input_tokens=34, output_tokens=187
18:41:29,291 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:41:29,292 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.37568131700391. input_tokens=34, output_tokens=79
18:41:32,852 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:41:32,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.514661416993476. input_tokens=34, output_tokens=76
18:41:53,784 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:41:53,785 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.879122604994336. input_tokens=34, output_tokens=81
18:42:00,435 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:42:00,436 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.582977070007473. input_tokens=34, output_tokens=83
18:42:13,241 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:42:13,243 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 43.95238041301491. input_tokens=34, output_tokens=132
18:42:21,895 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:42:21,896 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.11142987399944. input_tokens=34, output_tokens=80
18:42:33,281 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:42:33,282 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.84690138002043. input_tokens=34, output_tokens=99
18:42:35,70 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:42:35,72 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 101.3287735650083. input_tokens=34, output_tokens=308
18:42:42,113 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:42:42,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.871744367002975. input_tokens=34, output_tokens=79
18:42:50,533 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:42:50,535 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.6392615030054. input_tokens=34, output_tokens=79
18:43:00,124 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:43:00,125 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.843055628007278. input_tokens=34, output_tokens=72
18:43:03,49 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:43:03,51 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.979494127997896. input_tokens=34, output_tokens=77
18:43:18,131 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:43:18,132 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.597967467998387. input_tokens=34, output_tokens=80
18:43:30,946 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:43:30,947 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.896773403976113. input_tokens=34, output_tokens=83
18:43:36,129 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:43:36,131 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.01721320700017. input_tokens=34, output_tokens=159
18:43:52,719 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:43:52,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.588134113000706. input_tokens=34, output_tokens=102
18:44:01,770 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:44:01,771 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 25.640998145012418. input_tokens=34, output_tokens=76
18:44:22,792 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:44:22,793 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.073511775000952. input_tokens=34, output_tokens=92
18:44:22,805 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:44:22,807 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 82.68389855697751. input_tokens=34, output_tokens=229
18:44:29,834 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:44:29,835 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.063915250007994. input_tokens=34, output_tokens=80
18:44:49,216 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:44:49,217 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.42483033897588. input_tokens=34, output_tokens=76
18:44:49,230 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:44:49,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.42463618898182. input_tokens=34, output_tokens=76
18:44:55,614 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:44:55,615 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 25.780660137999803. input_tokens=34, output_tokens=74
18:45:08,386 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:45:08,387 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 97.44287490399438. input_tokens=34, output_tokens=292
18:45:17,717 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:45:17,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.50129848200595. input_tokens=34, output_tokens=81
18:45:24,993 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:45:24,995 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 35.764776297990466. input_tokens=34, output_tokens=99
18:45:34,895 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:45:34,896 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.281772138987435. input_tokens=34, output_tokens=113
18:45:43,53 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:45:43,54 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.66826643599779. input_tokens=34, output_tokens=101
18:45:45,725 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:45:45,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.008572463993914. input_tokens=34, output_tokens=76
18:46:02,560 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:46:02,561 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.66554485700908. input_tokens=34, output_tokens=85
18:46:24,288 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:46:24,290 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 59.296172878996. input_tokens=34, output_tokens=187
18:46:25,644 httpx INFO HTTP Request: POST http://ollama:11434/v1/chat/completions "HTTP/1.1 200 OK"
18:46:25,645 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.59108554999693. input_tokens=34, output_tokens=135
18:46:25,653 graphrag.index.operations.cluster_graph WARNING Graph has no nodes
18:46:25,657 datashaper.workflow.workflow ERROR Error executing verb "create_base_entity_graph" in create_base_entity_graph: Columns must be same length as key
Traceback (most recent call last):
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
             ^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/workflows/v1/subflows/create_base_entity_graph.py", line 53, in create_base_entity_graph
    output = await create_base_entity_graph_flow(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/flows/create_base_entity_graph.py", line 79, in create_base_entity_graph
    clustered = cluster_graph(
                ^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/operations/cluster_graph.py", line 90, in cluster_graph
    output[[level_to, to]] = pd.DataFrame(output[to].tolist(), index=output.index)
    ~~~~~~^^^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/pandas/core/frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/pandas/core/frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/pandas/core/indexers/utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
18:46:25,660 graphrag.callbacks.file_workflow_callbacks INFO Error executing verb "create_base_entity_graph" in create_base_entity_graph: Columns must be same length as key details=None
18:46:25,660 graphrag.index.run.run ERROR error running workflow create_base_entity_graph
Traceback (most recent call last):
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/run/run.py", line 274, in run_pipeline
    result = await _process_workflow(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/run/workflow.py", line 105, in _process_workflow
    result = await workflow.run(context, callbacks)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/datashaper/workflow/workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
             ^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/workflows/v1/subflows/create_base_entity_graph.py", line 53, in create_base_entity_graph
    output = await create_base_entity_graph_flow(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/flows/create_base_entity_graph.py", line 79, in create_base_entity_graph
    clustered = cluster_graph(
                ^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/graphrag/index/operations/cluster_graph.py", line 90, in cluster_graph
    output[[level_to, to]] = pd.DataFrame(output[to].tolist(), index=output.index)
    ~~~~~~^^^^^^^^^^^^^^^^
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/pandas/core/frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/pandas/core/frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "/workspaces/mictlan/.venv/lib/python3.11/site-packages/pandas/core/indexers/utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
18:46:25,662 graphrag.callbacks.file_workflow_callbacks INFO Error running pipeline! details=None
18:46:25,676 graphrag.cli.index ERROR Errors occurred during the pipeline run, see logs for more details.
